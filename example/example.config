TRAINING_TREEBANK_FILE=train.trees # Parsed training data, created by parser.jar or conll2tree.jar
INITIAL_SUBSAMPLE_SIZE=10 #  A new random subset of the specified size is chosen as a learning treebank for extracting rule candidates in each iteration. Bigger training subsets lead to longer training times, but increase the probability of finding a near-optimal new rule in each iteration. Should be at leat 4N, where N is the number of CPUs available for adequate load balancing. 
MAX_RULE_CROSSING_SCORE=0 #Bound on the effect on alignment monotonicity of the whole training corpus for candidate rules. Should be 0 or a negative number.
MIN_MATCHING_FEATURES=12 # For window size 4: 12 for exact matching, <12 for fuzzy matching. For window size 3: 10 for exact matching, <10 for fuzzy matching. For window size 2: 8 for exact matcing, <8 for fuzzy matching  The given value is adjusted automatically for nodes that have few children and thus cannot fulfill the given matching criterion. Small values yield very poor results.
PARALLEL_THREADS=10
RULE_OUTPUT_FILE=preordering.rules
MIN_REDUCTION_FACTOR=2.0 #Variance constraint for rules: Each new rule must reduce crossing score on n times as many sentences as number of sentences where it increases crossing score. For noisy data sets, a minimum reduction factor of 2.0 is recommended.
WINDOW_SIZE=4 #  Size of the sliding window during rule extraction. Values between 2 and 4 are supported.
USE_FEATURE_SUBSETS=y # If 'y', subsets of the matching context are also extracted as feature sets for candidate rules. 
LOGGING=q # (v[erbose]/q[uiet]),
MAX_WAITING_TIME_MINS=1# Maximum time in minutes that may elapse without any new rules being learned before training is stopped. Longer time limits will result in more rules being learned. For large datasets, a minimum of 10 minutes waiting time is recommended.
